{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e74e39-9b3b-4fc8-8959-5e69893abcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fb63d5-4517-4d98-8d40-e93aaf25b310",
   "metadata": {},
   "source": [
    "# Chapter 12 - Language Model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc41d708-3f14-4f60-b305-f918303e2899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='32768' class='' max='30252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      108.32% [32768/30252 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [Path('C:/Users/oneir/.fastai/data/human_numbers/train.txt'),Path('C:/Users/oneir/.fastai/data/human_numbers/valid.txt')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.HUMAN_NUMBERS)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c843f834-6011-47fc-9f9f-8b190fad722a",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56262141-b91d-45b5-8bb3-46654920bd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#9998) ['one \\n','two \\n','three \\n','four \\n','five \\n','six \\n','seven \\n','eight \\n','nine \\n','ten \\n'...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = L()\n",
    "\n",
    "with open(path/'train.txt') as f: lines += L(*f.readlines())\n",
    "with open(path/'valid.txt') as f: lines += L(*f.readlines())\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bfb6034-b75f-40b9-95ec-fc7006a16593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' . '.join(l.strip() for l in lines)\n",
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03aac462-7fd9-47e8-ab81-da0f6ff3981d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = text.split(' ')\n",
    "vocab = L(*tokens).unique()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd6b537b-2277-4dcc-8442-b779e490ef3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#63095) [0,1,2,1,3,1,4,1,5,1...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx = {word: index for index,word in enumerate(vocab)}\n",
    "nums = L(word2idx[token] for token in tokens)\n",
    "nums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1353c94-faf4-4131-8551-17dd4dfd2b85",
   "metadata": {},
   "source": [
    "## First simple LM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dbc44d-8121-4985-acbd-b2cf73b56ea8",
   "metadata": {},
   "source": [
    "We'll take 3 tokens and predict the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10ec355b-8a1d-418f-afc6-519b39d3c89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#21031) [(['one', '.', 'two'], '.'),(['.', 'three', '.'], 'four'),(['four', '.', 'five'], '.'),(['.', 'six', '.'], 'seven'),(['seven', '.', 'eight'], '.'),(['.', 'nine', '.'], 'ten'),(['ten', '.', 'eleven'], '.'),(['.', 'twelve', '.'], 'thirteen'),(['thirteen', '.', 'fourteen'], '.'),(['.', 'fifteen', '.'], 'sixteen')...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L((tokens[i:i+3], tokens[i+3]) for i in range(0,len(tokens)-4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a258faa-0fd4-4b1c-ba9b-ed3345840b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = L((tensor(nums[i:i+3]), nums[i+3]) for i in range(0,len(nums)-4, 3))\n",
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41b4b1cf-1d27-4a03-94ec-92fd385db029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    }
   ],
   "source": [
    "bs = 64\n",
    "cut = int(len(seqs) * .8)\n",
    "dls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b83c3330-8197-4b07-8a8f-c31f833318f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM1(Module):\n",
    "    def __init__(self, vocab_size, n_hidden):\n",
    "        # super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, n_hidden)\n",
    "        self.fc1 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.fc2 = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def _apply_net(self, x):\n",
    "        return self.fc1(self.embedding(x))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # first token\n",
    "        h = F.relu(self.fc1(self.embedding(x[:,0])))\n",
    "        \n",
    "        # second token\n",
    "        h = h + self.embedding(x[:,1])\n",
    "        h = F.relu(self.fc1(h))\n",
    "        \n",
    "        # third token\n",
    "        h = h + self.embedding(x[:,2])\n",
    "        h = F.relu(self.fc1(h))\n",
    "        \n",
    "        return self.fc2(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac26f4a2-5117-44cc-9a2c-9d2090bf9b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.825217</td>\n",
       "      <td>1.953809</td>\n",
       "      <td>0.467316</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.368626</td>\n",
       "      <td>1.787102</td>\n",
       "      <td>0.468267</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.410161</td>\n",
       "      <td>1.632404</td>\n",
       "      <td>0.489185</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.378835</td>\n",
       "      <td>1.602587</td>\n",
       "      <td>0.494176</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, LM1(len(vocab), 64), loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(4, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb270eb7-26e1-4580-a254-6de751c4b754",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af4cd1-7533-431b-aae5-3a56e6b3c1ce",
   "metadata": {},
   "source": [
    "Let's compare this to a baseline: predicting the most common token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81d39faf-a55d-4619-8f1e-6bd8213721fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(29), 'thousand', tensor(0.1517))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 0\n",
    "counts = torch.zeros(len(vocab))\n",
    "\n",
    "for _,y in dls.valid:\n",
    "    n += len(y)\n",
    "    for i in range_of(vocab): counts[i] += (y==i).sum()\n",
    "    \n",
    "idx = torch.argmax(counts)\n",
    "idx, vocab[idx.item()], counts[idx]/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b487898c-8e4f-4441-b75e-8cbaead3c9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
